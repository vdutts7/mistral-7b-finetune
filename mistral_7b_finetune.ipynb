{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "390sC684Lnj-"
      },
      "source": [
        "# 1. Download Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYpSoOm3HHmZ"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "\n",
        "!git clone https://github.com/mistralai/mistral-finetune.git\n",
        "\n",
        "!pip install -r /content/mistral-finetune/requirements.txt\n",
        "\n",
        "# Download model + set directory\n",
        "!wget https://models.mistralcdn.com/mistral-7b-v0-3/mistral-7B-v0.3.tar\n",
        "!DIR=/content/mistral_models && mkdir -p $DIR && tar -xf mistral-7B-v0.3.tar -C $DIR\n",
        "\n",
        "\n",
        "\n",
        "#_______________Optional___________________________________\n",
        "# Alternatively, you can download the model from Hugging Face\n",
        "\n",
        "# !pip install huggingface_hub\n",
        "# from huggingface_hub import snapshot_download\n",
        "# from pathlib import Path\n",
        "\n",
        "# mistral_models_path = Path.home().joinpath('mistral_models', '7B-v0.3')\n",
        "# mistral_models_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# snapshot_download(repo_id=\"mistralai/Mistral-7B-v0.3\", allow_patterns=[\"params.json\", \"consolidated.safetensors\", \"tokenizer.model.v3\"], local_dir=mistral_models_path)\n",
        "\n",
        "#! cp -r /root/mistral_models/7B-v0.3 /content/mistral_models\n",
        "#! rm -r /root/mistral_models/7B-v0.3\n",
        "\n",
        "!ls /content/mistral_models\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MWEfE4jLvdM"
      },
      "source": [
        "# 2. Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHATpHaNSwz1",
        "outputId": "2a7fc142-be4e-4426-e753-ab800670f5b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbtB8TiQSxWa"
      },
      "outputs": [],
      "source": [
        "# make a new directory called data\n",
        "!mkdir -p data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RS8xD62SzM_",
        "outputId": "ae9ac728-ff76-4022-b8d1-3b0e87fad50c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/data\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# navigate to this data directory\n",
        "%cd /content/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0HnziGHLCh4",
        "outputId": "b1a08dc0-85f6-430f-cde7-0fe605b72e0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ultrachat_chunk_eval.jsonl  ultrachat_chunk_train.jsonl\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# read data into a pandas dataframe\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_parquet('https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k/resolve/main/data/test_gen-00000-of-00001-3d4cd8309148a71f.parquet')\n",
        "\n",
        "# split data into training and evaluation\n",
        "df_train=df.sample(frac=0.95,random_state=200)\n",
        "df_eval=df.drop(df_train.index)\n",
        "\n",
        "# save data into .jsonl files\n",
        "df_train.to_json(\"ultrachat_chunk_train.jsonl\", orient=\"records\", lines=True)\n",
        "df_eval.to_json(\"ultrachat_chunk_eval.jsonl\", orient=\"records\", lines=True)\n",
        "\n",
        "\n",
        "!ls /content/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rY0D8JLgD9d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# navigate to the mistral-finetune directory\n",
        "%cd /content/mistral-finetune/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# some of the training data doesn't have the right format,\n",
        "# so we need to reformat the data into the correct format and skip the cases that doesn't have the right format:\n",
        "\n",
        "!python -m utils.reformat_data /content/data/ultrachat_chunk_train.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# eval data looking good\n",
        "!python -m utils.reformat_data /content/data/ultrachat_chunk_eval.jsonl"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
